{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T11:20:33.796797Z",
     "iopub.status.busy": "2024-11-28T11:20:33.796018Z",
     "iopub.status.idle": "2024-11-28T11:20:53.051081Z",
     "shell.execute_reply": "2024-11-28T11:20:53.050022Z",
     "shell.execute_reply.started": "2024-11-28T11:20:33.796762Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting onnxruntime-gpu\n",
      "  Downloading onnxruntime_gpu-1.20.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.19.0)\n",
      "Requirement already satisfied: timm in /opt/conda/lib/python3.10/site-packages (1.0.9)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (3.7.5)\n",
      "Requirement already satisfied: seaborn in /opt/conda/lib/python3.10/site-packages (0.12.2)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (5.9.3)\n",
      "Collecting coloredlogs (from onnxruntime-gpu)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: flatbuffers in /opt/conda/lib/python3.10/site-packages (from onnxruntime-gpu) (24.3.25)\n",
      "Requirement already satisfied: numpy>=1.21.6 in /opt/conda/lib/python3.10/site-packages (from onnxruntime-gpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from onnxruntime-gpu) (21.3)\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from onnxruntime-gpu) (3.20.3)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from onnxruntime-gpu) (1.13.3)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from torchvision) (2.4.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from timm) (6.0.2)\n",
      "Requirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (from timm) (0.25.1)\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm) (0.4.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pandas>=0.25 in /opt/conda/lib/python3.10/site-packages (from seaborn) (2.2.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.25->seaborn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.25->seaborn) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime-gpu)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (3.15.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (2024.6.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (4.12.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->onnxruntime-gpu) (1.3.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->torchvision) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->torchvision) (3.1.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->torchvision) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (2024.8.30)\n",
      "Downloading onnxruntime_gpu-1.20.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (291.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m291.5/291.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, onnxruntime-gpu\n",
      "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-gpu-1.20.1\n"
     ]
    }
   ],
   "source": [
    "!pip install onnxruntime-gpu torchvision timm matplotlib seaborn psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T12:38:01.339399Z",
     "iopub.status.busy": "2024-11-28T12:38:01.339054Z",
     "iopub.status.idle": "2024-11-28T12:40:17.543294Z",
     "shell.execute_reply": "2024-11-28T12:40:17.542443Z",
     "shell.execute_reply.started": "2024-11-28T12:38:01.339364Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the PyTorch model path:  /kaggle/input/imagesurfacedefectclassification/pytorch/efficientnet-b0-defect-classification-v1/1/fine_tuned_efficientnet.pth\n",
      "Enter the test data folder path:  /kaggle/input/testdataimageclassificationsurfacedefect/test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30/1753554454.py:66: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path, map_location=device)\n",
      "/tmp/ipykernel_30/1753554454.py:91: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(pytorch_model_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the path to save the ONNX model (including filename, e.g., /kaggle/working/model.onnx):  /kaggle/working/Working_Model.onnx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX model exported to /kaggle/working/Working_Model.onnx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the path to save the quantized ONNX model (including filename, e.g., /kaggle/working/quantized_model.onnx):  /kaggle/working/Quantized_Working_Model.onnx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized ONNX model saved to /kaggle/working/Quantized_Working_Model.onnx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0;93m2024-11-28 12:39:16.763371063 [W:onnxruntime:, transformer_memcpy.cc:74 ApplyImpl] 245 Memcpy nodes are added to the graph main_graph for CUDAExecutionProvider. It might have negative impact on performance (including unable to run CUDA graph). Set session_options.log_severity_level=1 to see the detail logs before this message.\u001b[m\n",
      "\u001b[0;93m2024-11-28 12:39:16.769833843 [W:onnxruntime:, session_state.cc:1168 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.\u001b[m\n",
      "\u001b[0;93m2024-11-28 12:39:16.769851776 [W:onnxruntime:, session_state.cc:1170 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.\u001b[m\n",
      "/tmp/ipykernel_30/1753554454.py:139: RuntimeWarning: overflow encountered in exp\n",
      "  sigmoid_outputs = 1 / (1 + np.exp(-ort_outs[0]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PyTorch Inference Results:\n",
      "Accuracy: 0.9671, Precision: 0.9873, Recall: 0.7091, F1 Score: 0.8254\n",
      "Time Taken: 11.33s, Memory Usage: 2.79GB\n",
      "\n",
      "Quantized ONNX Inference Results:\n",
      "Accuracy: 0.7570, Precision: 0.1650, Recall: 0.3000, F1 Score: 0.2129\n",
      "Time Taken: 60.62s, Memory Usage: 3.01GB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import psutil\n",
    "import onnxruntime as ort\n",
    "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
    "from torchvision.models import efficientnet_b0\n",
    "\n",
    "class DefectDataset(Dataset):\n",
    "    def __init__(self, folder, transform=None):\n",
    "        self.folder = folder\n",
    "        self.transform = transform\n",
    "        self.images = [f for f in os.listdir(folder) if f.endswith('.png') and not f.endswith('_GT.png')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.folder, self.images[idx])\n",
    "        gt_name = os.path.join(self.folder, self.images[idx].replace('.png', '_GT.png'))\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        label = 0  # label is defaulting to 0 (no defect)\n",
    "        if os.path.exists(gt_name):\n",
    "            label_image = plt.imread(gt_name)\n",
    "            label = int(np.max(label_image) > 0)  # ensuring that the label is binary\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# utility function for metrics\n",
    "def calculate_metrics(true_labels, pred_labels):\n",
    "    true_labels = np.array(true_labels).astype(int)\n",
    "    pred_labels = np.array(pred_labels).astype(int)\n",
    "\n",
    "    if len(np.unique(true_labels)) > 2 or len(np.unique(pred_labels)) > 2:\n",
    "        raise ValueError(\"Labels must be binary (0 or 1). Found more than two classes.\")\n",
    "\n",
    "    accuracy = accuracy_score(true_labels, pred_labels)\n",
    "    precision = precision_score(true_labels, pred_labels, zero_division=1)\n",
    "    recall = recall_score(true_labels, pred_labels, zero_division=1)\n",
    "    f1 = f1_score(true_labels, pred_labels, zero_division=1)\n",
    "    cm = confusion_matrix(true_labels, pred_labels)\n",
    "    return accuracy, precision, recall, f1, cm\n",
    "\n",
    "def pytorch_inference(model_path, test_folder, device):\n",
    "    image_size = (224, 224)\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "    ])\n",
    "    test_dataset = DefectDataset(test_folder, transform=test_transform)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    model = efficientnet_b0(weights=None)\n",
    "    num_classes = 1\n",
    "    model.classifier[1] = torch.nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "    state_dict = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    true_labels, pred_labels = [], []\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            preds = torch.sigmoid(outputs).cpu().numpy().round().astype(int)\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "            pred_labels.extend(preds.flatten())\n",
    "    end_time = time.time()\n",
    "\n",
    "    metrics = calculate_metrics(true_labels, pred_labels)\n",
    "    memory_usage = psutil.virtual_memory().used / (1024 ** 3)\n",
    "    return metrics, end_time - start_time, memory_usage\n",
    "\n",
    "def export_to_onnx(pytorch_model_path, device):\n",
    "    model = efficientnet_b0(weights=None)\n",
    "    num_classes = 1\n",
    "    model.classifier[1] = torch.nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "    state_dict = torch.load(pytorch_model_path, map_location=device)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    onnx_model_path = input(\"Enter the path to save the ONNX model (including filename, e.g., /kaggle/working/model.onnx): \")\n",
    "    if not onnx_model_path.endswith(\".onnx\"):\n",
    "        onnx_model_path += \".onnx\"\n",
    "\n",
    "    dummy_input = torch.randn(1, 3, 224, 224, device=device)\n",
    "    torch.onnx.export(\n",
    "        model,\n",
    "        dummy_input,\n",
    "        onnx_model_path,\n",
    "        opset_version=11,\n",
    "        input_names=[\"input\"],\n",
    "        output_names=[\"output\"],\n",
    "        dynamic_axes={\"input\": {0: \"batch_size\"}, \"output\": {0: \"batch_size\"}}\n",
    "    )\n",
    "\n",
    "    print(f\"ONNX model exported to {onnx_model_path}\")\n",
    "    return onnx_model_path\n",
    "\n",
    "def quantized_onnx_inference(onnx_model_path, test_folder):\n",
    "    image_size = (224, 224)\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "    ])\n",
    "    test_dataset = DefectDataset(test_folder, transform=test_transform)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    quantized_model_path = input(\"Enter the path to save the quantized ONNX model (including filename, e.g., /kaggle/working/quantized_model.onnx): \")\n",
    "    quantize_dynamic(onnx_model_path, quantized_model_path, weight_type=QuantType.QUInt8)\n",
    "    print(f\"Quantized ONNX model saved to {quantized_model_path}\")\n",
    "\n",
    "    ort_session = ort.InferenceSession(quantized_model_path, providers=[\"CUDAExecutionProvider\"])\n",
    "\n",
    "    true_labels, pred_labels = [], []\n",
    "    start_time = time.time()\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.numpy()\n",
    "        ort_inputs = {ort_session.get_inputs()[0].name: inputs}\n",
    "        ort_outs = ort_session.run(None, ort_inputs)\n",
    "\n",
    "        # applying sigmoid activation to ensure binary predictions\n",
    "        sigmoid_outputs = 1 / (1 + np.exp(-ort_outs[0]))\n",
    "        preds = np.round(sigmoid_outputs).astype(int)\n",
    "        \n",
    "        true_labels.extend(labels.numpy())\n",
    "        pred_labels.extend(preds.flatten())\n",
    "    end_time = time.time()\n",
    "\n",
    "    metrics = calculate_metrics(true_labels, pred_labels)\n",
    "    memory_usage = psutil.virtual_memory().used / (1024 ** 3)\n",
    "    return metrics, end_time - start_time, memory_usage\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pytorch_model_path = input(\"Enter the PyTorch model path: \")\n",
    "    test_folder = input(\"Enter the test data folder path: \")\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    pytorch_metrics, pytorch_time, pytorch_memory = pytorch_inference(pytorch_model_path, test_folder, device)\n",
    "    onnx_model_path = export_to_onnx(pytorch_model_path, device)\n",
    "    quantized_metrics, quantized_time, quantized_memory = quantized_onnx_inference(onnx_model_path, test_folder)\n",
    "\n",
    "    print(\"\\nPyTorch Inference Results:\")\n",
    "    print(f\"Accuracy: {pytorch_metrics[0]:.4f}, Precision: {pytorch_metrics[1]:.4f}, Recall: {pytorch_metrics[2]:.4f}, F1 Score: {pytorch_metrics[3]:.4f}\")\n",
    "    print(f\"Time Taken: {pytorch_time:.2f}s, Memory Usage: {pytorch_memory:.2f}GB\")\n",
    "\n",
    "    print(\"\\nQuantized ONNX Inference Results:\")\n",
    "    print(f\"Accuracy: {quantized_metrics[0]:.4f}, Precision: {quantized_metrics[1]:.4f}, Recall: {quantized_metrics[2]:.4f}, F1 Score: {quantized_metrics[3]:.4f}\")\n",
    "    print(f\"Time Taken: {quantized_time:.2f}s, Memory Usage: {quantized_memory:.2f}GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T12:53:12.037373Z",
     "iopub.status.busy": "2024-11-28T12:53:12.037014Z",
     "iopub.status.idle": "2024-11-28T12:54:18.101692Z",
     "shell.execute_reply": "2024-11-28T12:54:18.100729Z",
     "shell.execute_reply.started": "2024-11-28T12:53:12.037342Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the PyTorch model path:  /kaggle/input/imagesurfacedefectclassification/pytorch/efficientnet-b0-defect-classification-v1/1/fine_tuned_efficientnet.pth\n",
      "Enter the test data folder path:  /kaggle/input/testdataimageclassificationsurfacedefect/test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30/1090242834.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path, map_location=device)\n",
      "/tmp/ipykernel_30/1090242834.py:92: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(pytorch_model_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the path to save the ONNX model (including filename, e.g., /kaggle/working/model.onnx):  /kaggle/working/Fine-Tuned_EffNet.onnx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX model exported to /kaggle/working/Fine-Tuned_EffNet.onnx\n",
      "\n",
      "PyTorch Inference Results:\n",
      "Accuracy: 0.9671, Precision: 0.9873, Recall: 0.7091, F1 Score: 0.8254\n",
      "Time Taken: 10.06s, Memory Usage: 2.81GB\n",
      "\n",
      "Optimized ONNX Inference Results:\n",
      "Accuracy: 0.9671, Precision: 0.9873, Recall: 0.7091, F1 Score: 0.8254\n",
      "Time Taken: 10.17s, Memory Usage: 2.82GB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import psutil\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "from onnxruntime.transformers import optimizer\n",
    "from torchvision.models import efficientnet_b0\n",
    "\n",
    "class DefectDataset(Dataset):\n",
    "    def __init__(self, folder, transform=None):\n",
    "        self.folder = folder\n",
    "        self.transform = transform\n",
    "        self.images = [f for f in os.listdir(folder) if f.endswith('.png') and not f.endswith('_GT.png')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.folder, self.images[idx])\n",
    "        gt_name = os.path.join(self.folder, self.images[idx].replace('.png', '_GT.png'))\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        label = 0  # label is defaulting to 0\n",
    "        if os.path.exists(gt_name):\n",
    "            label_image = plt.imread(gt_name)\n",
    "            label = int(np.max(label_image) > 0)  # ensuring that the label is binary\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "#utility function for calculating metrics\n",
    "def calculate_metrics(true_labels, pred_labels):\n",
    "    true_labels = np.array(true_labels).astype(int)\n",
    "    pred_labels = np.array(pred_labels).astype(int)\n",
    "\n",
    "    if len(np.unique(true_labels)) > 2 or len(np.unique(pred_labels)) > 2:\n",
    "        raise ValueError(\"Labels must be binary (0 or 1). Found more than two classes.\")\n",
    "\n",
    "    accuracy = accuracy_score(true_labels, pred_labels)\n",
    "    precision = precision_score(true_labels, pred_labels, zero_division=1)\n",
    "    recall = recall_score(true_labels, pred_labels, zero_division=1)\n",
    "    f1 = f1_score(true_labels, pred_labels, zero_division=1)\n",
    "    cm = confusion_matrix(true_labels, pred_labels)\n",
    "    return accuracy, precision, recall, f1, cm\n",
    "\n",
    "def pytorch_inference(model_path, test_folder, device):\n",
    "    image_size = (224, 224)\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "    ])\n",
    "    test_dataset = DefectDataset(test_folder, transform=test_transform)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    model = efficientnet_b0(weights=None)\n",
    "    num_classes = 1\n",
    "    model.classifier[1] = torch.nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "    state_dict = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    true_labels, pred_labels = [], []\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            preds = torch.sigmoid(outputs).cpu().numpy().round().astype(int)\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "            pred_labels.extend(preds.flatten())\n",
    "    end_time = time.time()\n",
    "\n",
    "    metrics = calculate_metrics(true_labels, pred_labels)\n",
    "    memory_usage = psutil.virtual_memory().used / (1024 ** 3)\n",
    "    return metrics, end_time - start_time, memory_usage\n",
    "\n",
    "def export_to_onnx(pytorch_model_path, device):\n",
    "    model = efficientnet_b0(weights=None)\n",
    "    num_classes = 1\n",
    "    model.classifier[1] = torch.nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "    state_dict = torch.load(pytorch_model_path, map_location=device)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    onnx_model_path = input(\"Enter the path to save the ONNX model (including filename, e.g., /kaggle/working/model.onnx): \")\n",
    "    if not onnx_model_path.endswith(\".onnx\"):\n",
    "        onnx_model_path += \".onnx\"\n",
    "\n",
    "    dummy_input = torch.randn(1, 3, 224, 224, device=device) #ensure size is 224 by 224 pixels for smooth inference\n",
    "    torch.onnx.export(\n",
    "        model,\n",
    "        dummy_input,\n",
    "        onnx_model_path,\n",
    "        opset_version=11,\n",
    "        input_names=[\"input\"],\n",
    "        output_names=[\"output\"],\n",
    "        dynamic_axes={\"input\": {0: \"batch_size\"}, \"output\": {0: \"batch_size\"}}\n",
    "    )\n",
    "\n",
    "    print(f\"ONNX model exported to {onnx_model_path}\")\n",
    "    return onnx_model_path\n",
    "\n",
    "def optimized_onnx_inference(onnx_model_path, test_folder):\n",
    "    image_size = (224, 224)\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "    ])\n",
    "    test_dataset = DefectDataset(test_folder, transform=test_transform)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    # optimizing ONNX model using GraphOptimizationLevel, enabling all of them\n",
    "    optimized_model_path = onnx_model_path.replace(\".onnx\", \"_optimized.onnx\")\n",
    "    session_options = ort.SessionOptions()\n",
    "    session_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL\n",
    "\n",
    "    # setting ONNX Runtime session with CUDA\n",
    "    ort_session = ort.InferenceSession(onnx_model_path, session_options, providers=[\"CUDAExecutionProvider\"])\n",
    "\n",
    "    true_labels, pred_labels = [], []\n",
    "    start_time = time.time()\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.numpy()\n",
    "        ort_inputs = {ort_session.get_inputs()[0].name: inputs}\n",
    "        ort_outs = ort_session.run(None, ort_inputs)\n",
    "\n",
    "        # applying sigmoid activation to ensure binary predictions\n",
    "        sigmoid_outputs = 1 / (1 + np.exp(-ort_outs[0]))\n",
    "        preds = np.round(sigmoid_outputs).astype(int)\n",
    "        \n",
    "        true_labels.extend(labels.numpy())\n",
    "        pred_labels.extend(preds.flatten())\n",
    "    end_time = time.time()\n",
    "\n",
    "    metrics = calculate_metrics(true_labels, pred_labels)\n",
    "    memory_usage = psutil.virtual_memory().used / (1024 ** 3)\n",
    "    return metrics, end_time - start_time, memory_usage\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pytorch_model_path = input(\"Enter the PyTorch model path: \")\n",
    "    test_folder = input(\"Enter the test data folder path: \")\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    pytorch_metrics, pytorch_time, pytorch_memory = pytorch_inference(pytorch_model_path, test_folder, device)\n",
    "    onnx_model_path = export_to_onnx(pytorch_model_path, device)\n",
    "    optimized_metrics, optimized_time, optimized_memory = optimized_onnx_inference(onnx_model_path, test_folder)\n",
    "\n",
    "    print(\"\\nPyTorch Inference Results:\")\n",
    "    print(f\"Accuracy: {pytorch_metrics[0]:.4f}, Precision: {pytorch_metrics[1]:.4f}, Recall: {pytorch_metrics[2]:.4f}, F1 Score: {pytorch_metrics[3]:.4f}\")\n",
    "    print(f\"Time Taken: {pytorch_time:.2f}s, Memory Usage: {pytorch_memory:.2f}GB\")\n",
    "\n",
    "    print(\"\\nOptimized ONNX Inference Results:\")\n",
    "    print(f\"Accuracy: {optimized_metrics[0]:.4f}, Precision: {optimized_metrics[1]:.4f}, Recall: {optimized_metrics[2]:.4f}, F1 Score: {optimized_metrics[3]:.4f}\")\n",
    "    print(f\"Time Taken: {optimized_time:.2f}s, Memory Usage: {optimized_memory:.2f}GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see there is not much difference between the time and memory usage of Optimized ONNX model compared to Pytorch. And the results are the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6184035,
     "sourceId": 10039161,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 177125,
     "modelInstanceId": 154652,
     "sourceId": 181455,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
